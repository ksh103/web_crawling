{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c33fa5c",
   "metadata": {},
   "source": [
    "### 크롤링 핵심 코드 패턴 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed484d2d",
   "metadata": {},
   "source": [
    "##### 필요 라이브러리\n",
    "\n",
    "- requests\n",
    "\n",
    "  : 웹페이지 가져오기 라이브러리\n",
    "\n",
    "- bs4(BeautifulSoup)\n",
    "\n",
    "  : 웹페이지 분석 (크롤링) 라이브러리\n",
    "  \n",
    "  [HTML 요소 참고서](https://developer.mozilla.org/ko/docs/Web/HTML/Element)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaaae0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔금대출에도 DTI 규제 적용 검토\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 임포트\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 웹페이지 가져오기\n",
    "res = requests.get('http://v.media.daum.net/v/20170615203441266')\n",
    "\n",
    "# 웹페이지 파싱하기\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# 필요한 데이터 추출하기\n",
    "mydata = soup.find('title')\n",
    "\n",
    "# 추출한 데이터 활용하기\n",
    "print(mydata.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c946f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html =      \"<html> \\\n",
    "                <body> \\\n",
    "                        <h1 id='title'>[1]크롤링이란?</h1> \\\n",
    "                        <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p> \\\n",
    "                        <p id='body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p> \\\n",
    "                </body> \\\n",
    "            </html>\"\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "# 태그로 검색 방법\n",
    "# data = soup.find('p')\n",
    "# data = soup.find('h1')\n",
    "\n",
    "# HTML 언어 이해를 기반으로 크롤링 해보기\n",
    "# data = soup.find('p', class_='cssstyle')\n",
    "# data = soup.find('p', 'cssstyle')\n",
    "# data = soup.find('p', attrs = {'align':'center'})\n",
    "data = soup.find(id='body')\n",
    "\n",
    "print(data.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8711ea2",
   "metadata": {},
   "source": [
    "#### find_all() 함수 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f22f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "paragraph_data = soup.find_all('p')\n",
    "\n",
    "for paragraph in paragraph_data:\n",
    "    print(paragraph.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf9cab",
   "metadata": {},
   "source": [
    "#### HTMl/CSS 언어 이해를 기반으로 크롤링해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd23206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "금융당국이 급증하는 가계부채 증가세를 막기 위해 아파트 잔금대출에도 소득을 따져 대출한도를 정하는 총부채상환비율(DTI)을 적용하는 방안을 유력하게 검토하고 있다.\n",
      "지금은 집값을 기준으로 대출한도를 매기는 주택담보인정비율(LTV) 규제만 적용돼 소득이 없어도 집값의 70%를 빌려 잔금을 치르는 게 가능하다.\n",
      "앞으로 잔금대출에 DTI가 적용되면 소득이 없는 사람은 집값의 70% 대출 받는 게 어려워진다. 기사 제목과 주요 문장을 기반으로 자동요약한 결과입니다. 전체 맥락을 이해하기 위해서는 본문 보기를 권장합니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1) requests 라이브러리를 활용한 HTML 페이지 요청\n",
    "# 1-1) res 객체에 HTML 데이터가 저장되고, res.content로 데이터 추출 할 수 있음.\n",
    "res = requests.get('http://v.media.daum.net/v/20170615203441266')\n",
    "\n",
    "# print\n",
    "# 2) HTMl페이지 파싱 BeautifulSoup(HTMl 데이터, 파싱방법)\n",
    "# 2-1) BeautifulSoup 파싱방법\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# 3) 필요한 데이터 검색\n",
    "# mydata = soup.find('span',\"txt_info\")\n",
    "# mydata = soup.find('span',\"num_date\")\n",
    "mydata = soup.find('div',\"layer_util layer_summary\")\n",
    "\n",
    "# 4) 필요한 데이터 추출\n",
    "print(mydata.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29d86da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'입력 2017. 06. 15. 20:34'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = soup.find_all('span','txt_info')\n",
    "\n",
    "# for item in data:\n",
    "#     print(item.get_text())\n",
    "\n",
    "data[1].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392d85b",
   "metadata": {},
   "source": [
    "### 실전 크롤링과 강력한 크롤링 기술 Tip\n",
    "#### 예제 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a5fb9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "titles = soup.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abb15f",
   "metadata": {},
   "source": [
    "### 크롤링 강력한 팁 2 - 추출한 것에서 또 추출하기\n",
    "1. find()로 더 크게 감싸는 HTML 태그로 추출하고\n",
    "2. 다시 추출된 데이터에서 find_all()로 원하는 부분을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2a73a",
   "metadata": {},
   "source": [
    "#### 예제 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f5f368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# section = soup.find('ul', id = 'hobby_course_list')\n",
    "section = soup.find('ul', id = 'dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b3a29",
   "metadata": {},
   "source": [
    "### 크롤링 강력한 팁 3 - 파이썬 문자열 함수와 함께 쓰기\n",
    "\n",
    "* 데이터 전처리\n",
    "\n",
    "1. strip() 함수 사용해보기\n",
    "2. split() 함수 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "894583d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 강사가 실제 사용하는 자동 프로그램 소개\n",
      "2. 필요한 프로그램 설치 시연\n",
      "3. 데이터를 엑셀 파일로 만들기\n",
      "4. 엑셀 파일 이쁘게! 이쁘게!\n",
      "5. 나대신 주기적으로 파이썬 프로그램 실행하기\n",
      "6. 파이썬으로 슬랙(slack) 메신저에 글쓰기\n",
      "7. 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기\n",
      "8. 네이버 API 사용해서, 블로그에 글쓰기\n",
      "9. 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "section = soup.find('ul', id = 'dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for index,title in enumerate(titles):\n",
    "    print(str(index + 1) + '.', title.get_text().split('-')[1].split('[')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b58c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
